{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 5400)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "import copy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataframe\n",
    "holdings = pd.read_csv(\"c:\\\\kb_all\\\\all_3_1_21.csv\", low_memory=False)\n",
    "jan = pd.read_csv(\"c:\\\\ftf\\\\jan_2020.csv\", low_memory=False)\n",
    "feb = pd.read_csv(\"c:\\\\ftf\\\\feb_2020.csv\", low_memory=False)\n",
    "mar = pd.read_csv(\"c:\\\\ftf\\\\mar_2020.csv\", low_memory=False)\n",
    "apr = pd.read_csv(\"c:\\\\ftf\\\\apr_2020.csv\", low_memory=False)\n",
    "may = pd.read_csv(\"c:\\\\ftf\\\\may_2020.csv\", low_memory=False)\n",
    "jun = pd.read_csv(\"c:\\\\ftf\\\\june_2020.csv\", low_memory=False)\n",
    "jul = pd.read_csv(\"c:\\\\ftf\\\\july_2020.csv\", low_memory=False)\n",
    "aug = pd.read_csv(\"c:\\\\ftf\\\\aug_2020.csv\", low_memory=False)\n",
    "sep = pd.read_csv(\"c:\\\\ftf\\\\sept_2020.csv\", low_memory=False)\n",
    "octob = pd.read_csv(\"c:\\\\ftf\\\\oct_2020.csv\", low_memory=False)\n",
    "nov = pd.read_csv(\"c:\\\\ftf\\\\nov_2020.csv\", low_memory=False)\n",
    "dec = pd.read_csv(\"c:\\\\ftf\\\\dec_2020.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets into one\n",
    "ftf_ga = pd.concat([jan, feb, mar, apr, may, jun, jul, aug, sep, octob, nov, dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Trial Databases and print holdings\n",
    "holdings = holdings[~holdings['PackageName'].isin([\"Library Print Journals\", \"CINAHL Plus with Full Text\", \n",
    "                                                   \"Health Business  FullTEXT Elite\", \"Health Business FullTEXT Elite\", \n",
    "                                                   \"SocINDEX with Full Text\", \"MEDLINE with Full Text (EBSCO)\", \n",
    "                                                   \"Rehabilitation & Sports Medicine Source\", \"Dentistry & Oral Sciences Source\", \n",
    "                                                   \"SPORTDiscus with Full Text\", \"Education Source\", \n",
    "                                                   \"Biological & Agricultural Index Plus /(H.W. Wilson/)\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Select only eJournals, Newspapers, Newsletters, Proceedings\n",
    "ejournal = holdings[holdings['ResourceType'].isin(['Journal', 'Newspaper', 'Newsletter', 'Proceedings'])]\n",
    "#drop duplicates based on KBID\n",
    "ejournal_title = ejournal.drop_duplicates('KBID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Drop unnecessary columns\n",
    "ftf_ga.drop(['Event Category'], axis=1, inplace=True)\n",
    "###Drop rows with (not set)\n",
    "dropset = ftf_ga.loc[ftf_ga['Event Label'] != '(not set)']\n",
    "###Drop duplicates by article title \n",
    "dropdups = dropset.drop_duplicates('Page Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Replace and modify characters to increase possible title matches\n",
    "dropdups_copy = copy.deepcopy(dropdups)\n",
    "dropdups_copy['Event Label'] = dropdups_copy['Event Label'].str.replace('&amp;', '&').str.lower().str.replace('the ', '').str.replace('The ', '').str.replace(',', '')\\\n",
    ".str.replace('=','').str.replace(' - ',' ').str.replace('-',' ').str.replace(' & ', ' and ').str.replace('.', '').str.replace(r\"\\([\\w\\s)]+\\)\", \"\")\\\n",
    ".str.replace(r\":\\s.+\", \"\").str.strip()\n",
    "ejournal_title_only = ejournal_title['Title'].str.lower().str.replace('the ', '').str.replace('The ', '').str.replace(',', '')\\\n",
    ".str.replace('=','').str.replace(' - ',' ').str.replace('-',' ').str.replace(' & ', ' and ').str.replace('.', '').str.replace(r\"\\([\\w\\s)]+\\)\", \"\")\\\n",
    ".str.replace(r\":\\s.+\", \"\").str.strip()\n",
    "###Remove article title column\n",
    "dropdups_copy.drop(['Page Title'], axis=1, inplace=True)\n",
    "dropdups_copy.rename(columns={'Event Label':'Journal Title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename urls to database names\n",
    "def selector(x):\n",
    "    if 'direct' in x:\n",
    "        return 'EBSCO Database'\n",
    "    if 'pubmed' in x:\n",
    "        return 'PubMed'\n",
    "    if 'ncbi' in x:\n",
    "        return 'PubMed'\n",
    "    if 'webofknowledge' in x:\n",
    "        return 'Web of Science'\n",
    "    if 'wiley' in x:\n",
    "        return 'Wiley Online Library'\n",
    "    if 'ovid' in x:\n",
    "        return 'Ovid Database'\n",
    "    if 'scholar' in x:\n",
    "        return 'Google Scholar'\n",
    "    if 'eds' in x:\n",
    "        return 'EBSCO Database'\n",
    "    if 'embase' in x:\n",
    "        return 'EMBASE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = copy.deepcopy(dropdups_copy)\n",
    "result['Full Referrer'] = result['Full Referrer'].apply(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both dataframes on title\n",
    "df = pd.merge(result,ejournal_title_only, how='outer',left_on=['Journal Title'],right_on=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where Journal Title is nan. There are no titles in Google Analytics result that matches a title in our Knowledge Base (KB)\n",
    "df = df[df['Journal Title'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep rows whose title in google analytics does not match a title in the KB\n",
    "result_df = df[df['Journal Title'] != df['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = copy.deepcopy(result_df)\n",
    "final.drop(['Title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Full Referrer Click Counts\n",
    "referrer = final['Full Referrer'].value_counts().nlargest(20).sort_values().plot(kind='barh')\n",
    "plt.style.use('ggplot')\n",
    "plt.ylabel(\"Click Counts\", labelpad=14)\n",
    "plt.title(\"FTF Referrer Click Counts 2020\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Title Clicks\n",
    "title = final['Journal Title'].value_counts(sort=False).nlargest(20).sort_values().plot(kind='barh')\n",
    "plt.style.use('ggplot')\n",
    "plt.ylabel(\"Click Counts\", labelpad=14)\n",
    "plt.title(\"FTF Journal Title Click Counts 2020\", y=1.02);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
